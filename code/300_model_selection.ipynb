{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explored all the classifiers we learned so far with cross_val_score with their default parameters, and select the top 3 to do Gridsearch on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier,\\\n",
    "VotingClassifier, RandomForestClassifier,ExtraTreesClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC,SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nut_die=pd.read_csv('/Users/lettywu/dsi/Projects/project_3/project_3_letty/data/nutrition_vs_dietetics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nd_subreddit</th>\n",
       "      <th>nd_title_text</th>\n",
       "      <th>nd_length</th>\n",
       "      <th>nd_word_count</th>\n",
       "      <th>nd_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Please help me figure out what’s wrong with my...</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>0.2942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What Tests For Iron Deficiency? Looking at get...</td>\n",
       "      <td>335</td>\n",
       "      <td>54</td>\n",
       "      <td>0.6544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>How to get protein as a picky eater? [removed]</td>\n",
       "      <td>46</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Suffering with canker sores [removed]</td>\n",
       "      <td>37</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.4767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Good diets/work outs? I am trying to lose weig...</td>\n",
       "      <td>204</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nd_subreddit                                      nd_title_text  nd_length  \\\n",
       "0             1  Please help me figure out what’s wrong with my...         84   \n",
       "1             1  What Tests For Iron Deficiency? Looking at get...        335   \n",
       "2             1     How to get protein as a picky eater? [removed]         46   \n",
       "3             1              Suffering with canker sores [removed]         37   \n",
       "4             1  Good diets/work outs? I am trying to lose weig...        204   \n",
       "\n",
       "   nd_word_count  nd_sentiment  \n",
       "0             12        0.2942  \n",
       "1             54        0.6544  \n",
       "2              9        0.0000  \n",
       "3              5       -0.4767  \n",
       "4             39        0.2960  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nut_die.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.502927\n",
       "1    0.497073\n",
       "Name: nd_subreddit, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nut_die['nd_subreddit'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=nut_die['nd_title_text']\n",
    "y=nut_die['nd_subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the classification models I could use\n",
    "- Logistic Regression\n",
    "- Knn\n",
    "- Multinomial Naive Bayes\n",
    "- Bagging\n",
    "- DecisionTree,RandomForest,ExtraTree\n",
    "- Boosting(AdaBoost,GrandientBoost,XGBoost)\n",
    "- VotingClassifier\n",
    "- SVMs(LinearSVC,SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add customized stopwords into 'english' stopwords\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "newstopwords=['get','im','removed','ive','dont','rd','would','nutrition','deleted',\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo']\n",
    "stopwords.extend(newstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function here that would return corss_val_score for each classifier\n",
    "\n",
    "def classifier(estimator):\n",
    "    pipe_cvec=Pipeline([('cvec',CountVectorizer(stop_words=stopwords)),\n",
    "                  #('ss',StandardScaler(with_mean=False)),\n",
    "                  ('estimator',estimator)])\n",
    "    score_cvec=cross_val_score(pipe_cvec,X,y).mean()\n",
    "    \n",
    "    pipe_tvec=Pipeline([('tvec',TfidfVectorizer(stop_words=stopwords)),\n",
    "                  #('ss',StandardScaler(with_mean=False)),\n",
    "                  ('estimator',estimator)])\n",
    "    score_tvec=cross_val_score(pipe_tvec,X,y).mean()\n",
    "    \n",
    "    print(f'{estimator}:score_cvec {round(score_cvec,4)}\\n score_tvec {round(score_tvec,4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I tried to use StandardScaler for all of my classifier, the scores come out are worse than without StandardScaler**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score for each estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333\n"
     ]
    }
   ],
   "source": [
    "print (round(0.8333333,4)) # try out round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000):score_cvec 0.8816\n",
      " score_tvec 0.8921\n"
     ]
    }
   ],
   "source": [
    "classifier(LogisticRegression(max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('ss', StandardScaler(with_mean=False)),\n",
      "                ('knn', KNeighborsClassifier())]):score_cvec 0.7012\n",
      " score_tvec 0.6299\n"
     ]
    }
   ],
   "source": [
    "classifier(Pipeline([('ss', StandardScaler(with_mean=False)),\n",
    "                   ('knn',KNeighborsClassifier())]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB():score_cvec 0.8936\n",
      " score_tvec 0.8908\n"
     ]
    }
   ],
   "source": [
    "classifier(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifier():score_cvec 0.8195\n",
      " score_tvec 0.8537\n"
     ]
    }
   ],
   "source": [
    "classifier(BaggingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier():score_cvec 0.7964\n",
      " score_tvec 0.818\n"
     ]
    }
   ],
   "source": [
    "classifier(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier():score_cvec 0.871\n",
      " score_tvec 0.8766\n"
     ]
    }
   ],
   "source": [
    "classifier(RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier():score_cvec 0.8676\n",
      " score_tvec 0.89\n"
     ]
    }
   ],
   "source": [
    "classifier(ExtraTreesClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier():score_cvec 0.8478\n",
      " score_tvec 0.8397\n"
     ]
    }
   ],
   "source": [
    "classifier(AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier():score_cvec 0.8501\n",
      " score_tvec 0.8468\n"
     ]
    }
   ],
   "source": [
    "classifier(GradientBoostingClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:13:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:54] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:57] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:58] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:13:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:01] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:03] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:05] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:06] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
      "              gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None):score_cvec 0.8753\n",
      " score_tvec 0.872\n"
     ]
    }
   ],
   "source": [
    "classifier(XGBClassifier(use_label_encoder=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:14:14] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:42] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:14:55] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:08] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:21] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:36] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:15:51] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:16:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:16:22] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "VotingClassifier(estimators=[('LSVC', LinearSVC(max_iter=10000)),\n",
      "                             ('SVC', SVC()), ('Ada', AdaBoostClassifier()),\n",
      "                             ('Gra', GradientBoostingClassifier()),\n",
      "                             ('DecT', DecisionTreeClassifier()),\n",
      "                             ('knn_pipe',\n",
      "                              Pipeline(steps=[('ss',\n",
      "                                               StandardScaler(with_mean=False)),\n",
      "                                              ('knn',\n",
      "                                               KNeighborsClassifier())])),\n",
      "                             ('RaF', RandomForestClassifier()),\n",
      "                             ('XGB',\n",
      "                              XGBClassifier(base_score=None, b...\n",
      "                                            monotone_constraints=None,\n",
      "                                            n_estimators=100, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=None, reg_alpha=None,\n",
      "                                            reg_lambda=None,\n",
      "                                            scale_pos_weight=None,\n",
      "                                            subsample=None, tree_method=None,\n",
      "                                            use_label_encoder=False,\n",
      "                                            validate_parameters=None,\n",
      "                                            verbosity=None)),\n",
      "                             ('ExT', ExtraTreesClassifier()),\n",
      "                             ('Bag', BaggingClassifier()),\n",
      "                             ('Log', LogisticRegression()),\n",
      "                             ('MNB', MultinomialNB())]):score_cvec 0.8928\n",
      " score_tvec 0.8951\n"
     ]
    }
   ],
   "source": [
    "knn_pipe=Pipeline([('ss', StandardScaler(with_mean=False)),\n",
    "                   ('knn',KNeighborsClassifier())])\n",
    "vote=VotingClassifier([('LSVC',LinearSVC(max_iter=10000)),\n",
    "                      ('SVC',SVC()),\n",
    "                       ('Ada',AdaBoostClassifier()),\n",
    "                      ('Gra',GradientBoostingClassifier()),\n",
    "                      ('DecT',DecisionTreeClassifier()),\n",
    "                      ('knn_pipe',knn_pipe),\n",
    "                      ('RaF',RandomForestClassifier()),\n",
    "                      ('XGB',XGBClassifier(use_label_encoder=False)),\n",
    "                      ('ExT',ExtraTreesClassifier()),\n",
    "                      ('Bag',BaggingClassifier()),\n",
    "                      ('Log',LogisticRegression()),\n",
    "                      ('MNB',MultinomialNB())])\n",
    "classifier(vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(max_iter=10000):score_cvec 0.8598\n",
      " score_tvec 0.8888\n"
     ]
    }
   ],
   "source": [
    "classifier(LinearSVC(max_iter=10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC():score_cvec 0.8509\n",
      " score_tvec 0.8964\n"
     ]
    }
   ],
   "source": [
    "classifier(SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a dataframe to compare all the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_list=[LinearSVC(max_iter=10000),SVC(),AdaBoostClassifier(),\n",
    "                 GradientBoostingClassifier(),DecisionTreeClassifier(),\n",
    "                 Pipeline([('ss', StandardScaler(with_mean=False)),('knn',KNeighborsClassifier())]),\n",
    "                 RandomForestClassifier(),XGBClassifier(use_label_encoder=False),\n",
    "                 ExtraTreesClassifier(),BaggingClassifier(),LogisticRegression(),\n",
    "                 MultinomialNB(),vote]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:18:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:09] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:10] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:11] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:12] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:13] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:19] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:18:20] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:19:37] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:19:49] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:16] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:44] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:20:59] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:21:15] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:21:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:21:45] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "estimator_list=[]  #create empty lists for estimators and scores\n",
    "score_cvec_list=[]\n",
    "score_tvec_list=[]\n",
    "    \n",
    "for i in classifier_list:\n",
    "    estimator_list.append(i)\n",
    "    \n",
    "    pipe_cvec=Pipeline([('cvec',CountVectorizer(stop_words=stopwords)),\n",
    "                  ('estimator',i)])\n",
    "    score_cvec=cross_val_score(pipe_cvec,X,y).mean()\n",
    "    score_cvec_list.append(round(score_cvec,4))\n",
    "    \n",
    "    pipe_tvec=Pipeline([('tvec',TfidfVectorizer(stop_words=stopwords)),\n",
    "                  ('estimator',i)])\n",
    "    score_tvec=cross_val_score(pipe_tvec,X,y).mean()\n",
    "    score_tvec_list.append(round(score_tvec,4))\n",
    "    \n",
    "    #print(estimator_list,score_cvec_list,score_tvec_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe with the estimators and their scores\n",
    "\n",
    "scores_df=pd.DataFrame({'estimator':estimator_list,'score_cvec':score_cvec_list,\n",
    "                       'score_tvec':score_tvec_list}, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column that take average score of score from CountVectorizer \n",
    "#and score from TfidfVectorizer\n",
    "\n",
    "scores_df['score_avg']=round(scores_df.mean(axis=1),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of the classifier's name to add into the df, easier to read\n",
    "\n",
    "classifier_list_sim=['LinearSVC','SVC','AdaBoostClassifier','GradientBoostingClassifier',\n",
    "                    'DecisionTreeClassifier','KNeighborsClassifier','RandomForestClassifier',\n",
    "                    'XGBClassifier','ExtraTreesClassifier','BaggingClassifier',\n",
    "                    'LogisticRegression','MultinomialNB','VotingClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['estimator']=classifier_list_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>score_cvec</th>\n",
       "      <th>score_tvec</th>\n",
       "      <th>score_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>0.8922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.8816</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesClassifier</td>\n",
       "      <td>0.8715</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.8743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.8509</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>0.8736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>0.8720</td>\n",
       "      <td>0.8736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.8486</td>\n",
       "      <td>0.8490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>0.8438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.8297</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.8366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.7012</td>\n",
       "      <td>0.6299</td>\n",
       "      <td>0.6656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     estimator  score_cvec  score_tvec  score_avg\n",
       "12            VotingClassifier      0.8903      0.8959     0.8931\n",
       "11               MultinomialNB      0.8936      0.8908     0.8922\n",
       "10          LogisticRegression      0.8816      0.8921     0.8868\n",
       "8         ExtraTreesClassifier      0.8715      0.8850     0.8782\n",
       "6       RandomForestClassifier      0.8745      0.8814     0.8780\n",
       "0                    LinearSVC      0.8598      0.8888     0.8743\n",
       "1                          SVC      0.8509      0.8964     0.8736\n",
       "7                XGBClassifier      0.8753      0.8720     0.8736\n",
       "3   GradientBoostingClassifier      0.8493      0.8486     0.8490\n",
       "2           AdaBoostClassifier      0.8478      0.8397     0.8438\n",
       "9            BaggingClassifier      0.8297      0.8435     0.8366\n",
       "4       DecisionTreeClassifier      0.7900      0.8147     0.8024\n",
       "5         KNeighborsClassifier      0.7012      0.6299     0.6656"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by=['score_avg'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`looks like the VotingClassifier and the Miltinomial Naive Bayes Classifier are really good just with the default parameters` \n",
    "\n",
    "`I am using the default metric which is accuracy for classification, because Accuracy is used when the True Positives and True negatives are more important while F1-score is used when the False Negatives and False Positives are crucial.`\n",
    "\n",
    "`Also, I want to maximize my TP and TN for my problem statements, I want to predit Nutrition subreddit that is Nutrition subreddit, and predit Dietetics subreddit that is Dietetics subreddit`\n",
    "\n",
    "https://medium.com/analytics-vidhya/accuracy-vs-f1-score-6258237beca2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
